There are 5 main steps for any software design:
1.Gathering all functional and non-functional requirements.
2.High-Level abstraction
3.Low-Level abstraction
4.Write skeleton code.
5.Implement complete code.

1.Gathering all functional and non-functional requirements:-
----------------------------------------------------------
Non-Functional requirements:-
----------------------------------------------------------
i.Traffic is not evenly distributed (may be executed once or more)
ii.Allowing anonymous users
iii. quick search functionality
iv.The web crawler should not get stuck in an infinite loop 
v.Pages need to be crawled regularly to ensure updation.


Functional requirements:-
-----------------------------------------------------------
i.Crawling a list of urls
ii. Generating  reverse index of words to pages for search
iii.Generateing titles and templates for pages
iv.Title and snippets/templates are not dynamic, they remain static(unchanged)
v.User inputs a search term and gets the desired result



2. High-Level abstraction   (generally done using use-case diagrams)
The Client sends a request to the Web Server, running as a reverse proxy
The Web Server forwards the request to the Query API server
The Query API server does the following:
Parses the query
Normalizes capitalization
Fixes typos
Removes markup
Breaks up the text into terms
Converts the query to use boolean operations
Uses the Reverse Index Service to find documents matching the query
The Reverse Index Service ranks the matching results and returns the top ones
Uses the Document Service to return titles of the particular search

3.1=Low-Level abstraction ( Using class diagrams)

The Crawler Service processes each page link by doing the following in a loop:
Takes the top ranked page link to crawl
Checks crawled_links in the NoSQL Database for an entry with a similar page signature
If we have a similar page, reduces the priority of the page link
This prevents us from getting into a cycle
Continue
Else, crawls the link
Adds a job to the Reverse Index Service queue to generate a reverse index
Adds a job to the Document Service queue to generate a static title and snippet
Generates the page signature
Removes the link from links_to_crawl in the NoSQL Database
Inserts the page link and signature to crawled_links in the NoSQL Database

NOTE:-
----
Steps 4 and 5 are implemented after the design phase.

The overall design will be implemented based on the factors and components mentioned below:
1.Scalability
2.Performance
3.Latency & Throughput
4.CAP Theorem
5.DNS(Domain Name System)
6.CDN(Content Delivery Networks)
7.Load balancers & Reverse Proxy
8.Microservices
9.Databases(SQL and NoSQL)
10.Caching and message queues.

We can use Redis will be used as the NoSQL database for this application due to its providing functionalities. 
